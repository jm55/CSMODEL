{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "189a28d2",
   "metadata": {},
   "source": [
    "### 1. Dataset Representation\n",
    "\n",
    "- About the Dataset<br>\n",
    "\n",
    "The data was provided by Our World in Data (OWID). The file contains different data values that could help paint a better image of a countryâ€™s status for COVID-19. The version used in this project will be the July 15, 2021 release of the dataset, however OWID attempts both daily and weekly update of data whenever possible, thus ensuring that the data they provide is the latest possible.\n",
    "\n",
    "- Collection Process and its Implications<br>\n",
    "\n",
    "The collection was done by the Our World in Data Group which is a research group that focuses on research and aggregation of data in a single accessible repository for the purposes of getting a better picture or even solving world problems that can benefit all of mankind. For the specific dataset, they made use of all possible available data that is publicly released by governments of all nations in the world. According to OWID, the data was collected from the following sources which include:\n",
    "    \n",
    "    1. COVID-19 Data Repository of Johns Hopkins University\n",
    "    2. National Government Reports\n",
    "    3. Oxford COVID-19 Government Response Tracker, Blavatnik School of Government\n",
    "    4. United Nations Data (for demographics related data)\n",
    "    5. World Bank Data (for demographics related data)\n",
    "    \n",
    "The data implies that the data presented assumes to be the latest data possible, with its validity ultimately depending on each government's transparency and accuracy with the data they are reporting publicly and to John Hopkins University.\n",
    "    <br>\n",
    "- Structure of Dataset of the File<br>\n",
    "\n",
    "    The dataset's structure consists of 102,475 observations with 60 variables available. The structure goes on every country's date when it reported either its first COVID-19 case or first COVID-19 test. The dataset was already distributed publicly on a single file containing all of the relevant information possible. There is however other datasets which contain specific and specialized versions of the current dataset we are using that is also available for use on OWID's Github repository.\n",
    "    \n",
    "    The list of locations are a mixture of contients and actual countries, as recognized by OWID, which may or may not be legally recognized by the international community.\n",
    "    \n",
    "    <br>\n",
    "- About the Variables<br>\n",
    "    \n",
    "    The dataset has 60 variables, most of which relate to COVID-19 related numbers such as cases, deaths, recoveries, vaccinations among others, as well as demographic data such as GDP per capita, HDI, median age, population, population density among others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5de9a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING LIBRARIES...\n",
      "AUTOMATED MODE: True\n",
      "Raw Dataframe Shape: (102475, 60) \n",
      " =================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 102475 entries, 0 to 102474\n",
      "Data columns (total 60 columns):\n",
      " #   Column                                 Non-Null Count   Dtype  \n",
      "---  ------                                 --------------   -----  \n",
      " 0   iso_code                               102475 non-null  object \n",
      " 1   continent                              97689 non-null   object \n",
      " 2   location                               102475 non-null  object \n",
      " 3   date                                   102475 non-null  object \n",
      " 4   total_cases                            98594 non-null   float64\n",
      " 5   new_cases                              98591 non-null   float64\n",
      " 6   new_cases_smoothed                     97581 non-null   float64\n",
      " 7   total_deaths                           88371 non-null   float64\n",
      " 8   new_deaths                             88527 non-null   float64\n",
      " 9   new_deaths_smoothed                    97581 non-null   float64\n",
      " 10  total_cases_per_million                98070 non-null   float64\n",
      " 11  new_cases_per_million                  98067 non-null   float64\n",
      " 12  new_cases_smoothed_per_million         97062 non-null   float64\n",
      " 13  total_deaths_per_million               87860 non-null   float64\n",
      " 14  new_deaths_per_million                 88016 non-null   float64\n",
      " 15  new_deaths_smoothed_per_million        97062 non-null   float64\n",
      " 16  reproduction_rate                      82782 non-null   float64\n",
      " 17  icu_patients                           10688 non-null   float64\n",
      " 18  icu_patients_per_million               10688 non-null   float64\n",
      " 19  hosp_patients                          12916 non-null   float64\n",
      " 20  hosp_patients_per_million              12916 non-null   float64\n",
      " 21  weekly_icu_admissions                  951 non-null     float64\n",
      " 22  weekly_icu_admissions_per_million      951 non-null     float64\n",
      " 23  weekly_hosp_admissions                 1614 non-null    float64\n",
      " 24  weekly_hosp_admissions_per_million     1614 non-null    float64\n",
      " 25  new_tests                              45788 non-null   float64\n",
      " 26  total_tests                            45457 non-null   float64\n",
      " 27  total_tests_per_thousand               45457 non-null   float64\n",
      " 28  new_tests_per_thousand                 45788 non-null   float64\n",
      " 29  new_tests_smoothed                     53305 non-null   float64\n",
      " 30  new_tests_smoothed_per_thousand        53305 non-null   float64\n",
      " 31  positive_rate                          49803 non-null   float64\n",
      " 32  tests_per_case                         49173 non-null   float64\n",
      " 33  tests_units                            54997 non-null   object \n",
      " 34  total_vaccinations                     18050 non-null   float64\n",
      " 35  people_vaccinated                      17196 non-null   float64\n",
      " 36  people_fully_vaccinated                14334 non-null   float64\n",
      " 37  new_vaccinations                       15041 non-null   float64\n",
      " 38  new_vaccinations_smoothed              31499 non-null   float64\n",
      " 39  total_vaccinations_per_hundred         18050 non-null   float64\n",
      " 40  people_vaccinated_per_hundred          17196 non-null   float64\n",
      " 41  people_fully_vaccinated_per_hundred    14334 non-null   float64\n",
      " 42  new_vaccinations_smoothed_per_million  31499 non-null   float64\n",
      " 43  stringency_index                       85982 non-null   float64\n",
      " 44  population                             101817 non-null  float64\n",
      " 45  population_density                     95179 non-null   float64\n",
      " 46  median_age                             91455 non-null   float64\n",
      " 47  aged_65_older                          90429 non-null   float64\n",
      " 48  aged_70_older                          90950 non-null   float64\n",
      " 49  gdp_per_capita                         91824 non-null   float64\n",
      " 50  extreme_poverty                        61921 non-null   float64\n",
      " 51  cardiovasc_death_rate                  91810 non-null   float64\n",
      " 52  diabetes_prevalence                    94235 non-null   float64\n",
      " 53  female_smokers                         71798 non-null   float64\n",
      " 54  male_smokers                           70751 non-null   float64\n",
      " 55  handwashing_facilities                 46133 non-null   float64\n",
      " 56  hospital_beds_per_thousand             83618 non-null   float64\n",
      " 57  life_expectancy                        97312 non-null   float64\n",
      " 58  human_development_index                91948 non-null   float64\n",
      " 59  excess_mortality                       3624 non-null    float64\n",
      "dtypes: float64(55), object(5)\n",
      "memory usage: 46.9+ MB\n",
      "None\n",
      "Location List: ['Afghanistan' 'Africa' 'Albania' 'Algeria' 'Andorra' 'Angola' 'Anguilla'\n",
      " 'Antigua and Barbuda' 'Argentina' 'Armenia' 'Aruba' 'Asia' 'Australia'\n",
      " 'Austria' 'Azerbaijan' 'Bahamas' 'Bahrain' 'Bangladesh' 'Barbados'\n",
      " 'Belarus' 'Belgium' 'Belize' 'Benin' 'Bermuda' 'Bhutan' 'Bolivia'\n",
      " 'Bonaire Sint Eustatius and Saba' 'Bosnia and Herzegovina' 'Botswana'\n",
      " 'Brazil' 'British Virgin Islands' 'Brunei' 'Bulgaria' 'Burkina Faso'\n",
      " 'Burundi' 'Cambodia' 'Cameroon' 'Canada' 'Cape Verde' 'Cayman Islands'\n",
      " 'Central African Republic' 'Chad' 'Chile' 'China' 'Colombia' 'Comoros'\n",
      " 'Congo' 'Cook Islands' 'Costa Rica' \"Cote d'Ivoire\" 'Croatia' 'Cuba'\n",
      " 'Curacao' 'Cyprus' 'Czechia' 'Democratic Republic of Congo' 'Denmark'\n",
      " 'Djibouti' 'Dominica' 'Dominican Republic' 'Ecuador' 'Egypt'\n",
      " 'El Salvador' 'Equatorial Guinea' 'Eritrea' 'Estonia' 'Eswatini'\n",
      " 'Ethiopia' 'Europe' 'European Union' 'Faeroe Islands' 'Falkland Islands'\n",
      " 'Fiji' 'Finland' 'France' 'French Polynesia' 'Gabon' 'Gambia' 'Georgia'\n",
      " 'Germany' 'Ghana' 'Gibraltar' 'Greece' 'Greenland' 'Grenada' 'Guatemala'\n",
      " 'Guernsey' 'Guinea' 'Guinea-Bissau' 'Guyana' 'Haiti' 'Honduras'\n",
      " 'Hong Kong' 'Hungary' 'Iceland' 'India' 'Indonesia' 'International'\n",
      " 'Iran' 'Iraq' 'Ireland' 'Isle of Man' 'Israel' 'Italy' 'Jamaica' 'Japan'\n",
      " 'Jersey' 'Jordan' 'Kazakhstan' 'Kenya' 'Kiribati' 'Kosovo' 'Kuwait'\n",
      " 'Kyrgyzstan' 'Laos' 'Latvia' 'Lebanon' 'Lesotho' 'Liberia' 'Libya'\n",
      " 'Liechtenstein' 'Lithuania' 'Luxembourg' 'Macao' 'Madagascar' 'Malawi'\n",
      " 'Malaysia' 'Maldives' 'Mali' 'Malta' 'Marshall Islands' 'Mauritania'\n",
      " 'Mauritius' 'Mexico' 'Micronesia (country)' 'Moldova' 'Monaco' 'Mongolia'\n",
      " 'Montenegro' 'Montserrat' 'Morocco' 'Mozambique' 'Myanmar' 'Namibia'\n",
      " 'Nauru' 'Nepal' 'Netherlands' 'New Caledonia' 'New Zealand' 'Nicaragua'\n",
      " 'Niger' 'Nigeria' 'Niue' 'North America' 'North Macedonia'\n",
      " 'Northern Cyprus' 'Norway' 'Oceania' 'Oman' 'Pakistan' 'Palestine'\n",
      " 'Panama' 'Papua New Guinea' 'Paraguay' 'Peru' 'Philippines' 'Pitcairn'\n",
      " 'Poland' 'Portugal' 'Qatar' 'Romania' 'Russia' 'Rwanda' 'Saint Helena'\n",
      " 'Saint Kitts and Nevis' 'Saint Lucia' 'Saint Vincent and the Grenadines'\n",
      " 'Samoa' 'San Marino' 'Sao Tome and Principe' 'Saudi Arabia' 'Senegal'\n",
      " 'Serbia' 'Seychelles' 'Sierra Leone' 'Singapore'\n",
      " 'Sint Maarten (Dutch part)' 'Slovakia' 'Slovenia' 'Solomon Islands'\n",
      " 'Somalia' 'South Africa' 'South America' 'South Korea' 'South Sudan'\n",
      " 'Spain' 'Sri Lanka' 'Sudan' 'Suriname' 'Sweden' 'Switzerland' 'Syria'\n",
      " 'Taiwan' 'Tajikistan' 'Tanzania' 'Thailand' 'Timor' 'Togo' 'Tonga'\n",
      " 'Trinidad and Tobago' 'Tunisia' 'Turkey' 'Turkmenistan'\n",
      " 'Turks and Caicos Islands' 'Tuvalu' 'Uganda' 'Ukraine'\n",
      " 'United Arab Emirates' 'United Kingdom' 'United States' 'Uruguay'\n",
      " 'Uzbekistan' 'Vanuatu' 'Vatican' 'Venezuela' 'Vietnam'\n",
      " 'Wallis and Futuna' 'World' 'Yemen' 'Zambia' 'Zimbabwe']\n"
     ]
    }
   ],
   "source": [
    "print(\"LOADING LIBRARIES...\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "bar = \"=================================\"\n",
    "automated = True #Manual entry or pre-defined entries\n",
    "print(\"AUTOMATED MODE:\",automated)\n",
    "\n",
    "#Code for data preparation\n",
    "#PREPARE FILES AND RAW DATAFRAME\n",
    "raw_df = None\n",
    "if(not automated):\n",
    "    filename = input(\"Enter Filename of CSV file (including .csv): \")\n",
    "    raw_df = pd.read_csv(filename)\n",
    "else:\n",
    "    raw_df = pd.read_csv(\"COVID_7_15.csv\")\n",
    "#Raw file reading: make use of covid_df.readline() to retrieve a str line (as str) from\n",
    "\n",
    "print(\"Raw Dataframe Shape:\", raw_df.shape,\"\\n\",bar)\n",
    "print(raw_df.info())\n",
    "print(\"Location List:\",raw_df[\"location\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed20c65",
   "metadata": {},
   "source": [
    "### 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dff5d27",
   "metadata": {},
   "source": [
    "Given that there are a lot of nations and variables to consider, it has been decided to reduce to scope of nations to just the ASEAN nations as well as the World as a baseline. The consideration for ASEAN nations was made because of the following reasons:\n",
    "\n",
    "1. Near proximity\n",
    "2. Economic integration\n",
    "3. Similar level economies and populations\n",
    "\n",
    "This could help us determine the COVID-19 status of the Philippines to its neighbors as well as the World if ever it is applicable.\n",
    "\n",
    "The most of the columns are to be ommitted since it contains pre-treated values, specialized values, or varying values (in terms of the unit of measurement).\n",
    "\n",
    "Some of the columns retained are:\n",
    "- 'total_cases'\n",
    "- 'new_cases'\n",
    "- 'total_deaths'\n",
    "- 'new_deaths'\n",
    "- 'total_vaccinations'\n",
    "- 'people_vaccinated'\n",
    "- 'people_fully_vaccinated'\n",
    "- 'new_vaccinations'\n",
    "- 'stringency_index'\n",
    "- 'population'\n",
    "- 'gdp_per_capita'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c27719b",
   "metadata": {},
   "source": [
    "The script below crunches the raw data and produces a covid_df containing:\n",
    "1. World COVID-19 Data (from OWID)\n",
    "2. ASEAN COVID-19 Data (Containing 10 Countries, including the Philippines)\n",
    "3. Philippine COVID-19 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2db3cc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING ADDITIONAL LIBRARIES...\n",
      "DROPPING COLUMNS...\n",
      "FILTERING COUNTRIES...\n",
      "DATA CLEANUP (NaN->0)...\n",
      "AGGREGATING ASEAN COUNTRIES...\n",
      "WRITING CHECKPOINT...\n",
      "Checkpoint Complete: asean_checkpoint\n",
      "COMBINING DATAFRAMES...\n",
      "Remaining iso_codes: ['MDL_SEA' 'BRN' 'KHM' 'IDN' 'LAO' 'MYS' 'MMR' 'PHL' 'SGP' 'THA' 'VNM'\n",
      " 'OWID_WRL']\n",
      "FILE PROCESSING COMPLETE\n"
     ]
    }
   ],
   "source": [
    "#CSMODEL: COVID-19 Dataset\n",
    "#Crunches data of selected countries to a grouped one\n",
    "#Originally came from a separate \n",
    "\n",
    "print(\"LOADING ADDITIONAL LIBRARIES...\")\n",
    "import re\n",
    "\n",
    "#GLOBAL VARIABLES\n",
    "checkpoint = True\n",
    "NaN = float(\"nan\")\n",
    "group_pop = 0 #Placeholder for the population of group of nations specified.\n",
    "\n",
    "#CUSTOM FUNCTIONS\n",
    "def sortbydate(df): #Sorts and returns a given DataFrame on the 'date' column using MergeSort.\n",
    "    date_values = df['date'].unique()\n",
    "    date_values = np.sort(date_values,kind='mergesort')\n",
    "    return date_values\n",
    "def fillZeros(size): #Returns a list of zeros from a specified size\n",
    "    return np.zeros(size).tolist()\n",
    "def writeCheckpoint(df, filename): #Writes a given DataFrame to a CSV file\n",
    "    if(checkpoint):\n",
    "        print(\"WRITING CHECKPOINT...\")\n",
    "        df.to_csv(filename+\".csv\",index=False)\n",
    "        print(\"Checkpoint Complete:\",filename)\n",
    "def aggregator(src_df,iso_code,continent,location,count): #Aggregates the given DataFrame to a grouped version\n",
    "    tmp_df = pd.DataFrame(columns=toRetain) \n",
    "    for i in range(dateCount):\n",
    "        sp_date = date_values[i] #Specified date\n",
    "        filtered_df = src_df[src_df['date']==sp_date] #Series of nations with specified date\n",
    "        observations = filtered_df.shape[0]\n",
    "        if(observations == count): #Will run only if all countries listed are there\n",
    "            id = [iso_code,continent,location,sp_date] #Default identifiers for ASEAN\n",
    "            data = fillZeros(len(toRetainData))\n",
    "            for j in range(observations):\n",
    "                #add current data with the retrieved data\n",
    "                retrieve = filtered_df[toRetainData].iloc[j].tolist()\n",
    "                #print(retrieve)\n",
    "                data = list(map(lambda x,y:x+y,retrieve,data))\n",
    "            #Make values in average if they are based on trends (Keyword: new, per_xxxx)\n",
    "            #0-3 = iso_code,continent,location,date; equated to id\n",
    "            data[1] = data[1]/observations #new cases\n",
    "            data[3] = data[3]/observations #new deaths\n",
    "            data[6] = data[6]/observations #new_vaccinations\n",
    "            data[8] = data[8]/observations #stringency_index\n",
    "            data[9] = group_pop #population\n",
    "            data[10] = data[10]/observations #gdp_per_capita\n",
    "            result = id+data\n",
    "            tmp_df.loc[tmp_df.shape[0]] = result #\"ADDS\" THE RESULTING LIST AT THE END OF THE DATAFRAME\n",
    "    return tmp_df\n",
    "def dateRange(df): #Finds the lowest and highest date recorded.\n",
    "    date_values = df['date'].unique()\n",
    "    date_values = np.sort(date_values,kind='mergesort')\n",
    "    dateCount = date_values.size\n",
    "    return [date_values[0], date_values[len(date_values)-1]] #the latest possible data maybe incomplete thus the day prior the latest will be used\n",
    "\n",
    "#PREPARE FILES AND RAW DATAFRAME\n",
    "covid_df = raw_df.copy(deep=True)\n",
    "#Raw file reading: make use of covid_df.readline() to retrieve a str line (as str) from\n",
    "\n",
    "#DATE SORTING AND VALUES\n",
    "date_values = sortbydate(covid_df)\n",
    "dateCount = date_values.size\n",
    "\n",
    "#COLUMNS TO RETAIN\n",
    "toRetain = ['iso_code','continent','location','date','total_cases','new_cases','total_deaths','new_deaths','total_vaccinations','people_vaccinated','people_fully_vaccinated','new_vaccinations','stringency_index',\n",
    "            'population','gdp_per_capita']\n",
    "toRetainData = toRetain[4:]\n",
    "identifiers = toRetain[0:4]\n",
    "#LIST OF ONLY DATA THAT CAN BE USED IN A COLLECTIVE MANNER (AS USED BY OWID ITSELF)\n",
    "forCollective = ['total_cases','new_cases','new_cases_smoothed','total_deaths','new_deaths','new_deaths_smoothed','total_cases_per_million'\n",
    "                ,'new_cases_per_million','new_cases_smoothed_per_million','total_deaths_per_million','new_deaths_per_million','new_deaths_smoothed_per_million','total_vaccinations'\n",
    "                ,'people_vaccinated','people_fully_vaccinated','new_vaccinations','new_vaccinations_smoothed','total_vaccinations_per_hundred','people_vaccinated_per_hundred'\n",
    "                ,'people_fully_vaccinated_per_hundred','new_vaccinations_smoothed_per_million','population']\n",
    "targetCountries = ['PHL','BRN','KHM','IDN','SGP','LAO','THA','MYS','MMR','VNM'] #CHANGE CHOICES FOR TARGET COUNTRIES TO GROUP\n",
    "\n",
    "#COLUMN FLAGS\n",
    "raw_cols = covid_df.columns.tolist() #ALL COLUMNS AVAILABLE\n",
    "raw_dataCol = list(set(raw_cols)-set(identifiers)) #DATA ONLY COLUMNS\n",
    "\n",
    "#DROP COLUMNS\n",
    "print(\"DROPPING COLUMNS...\")\n",
    "toDrop = identifiers.copy()\n",
    "toDrop = list(set(covid_df.columns.tolist()) - set(toRetain))\n",
    "covid_df = covid_df.drop(columns=toDrop)\n",
    "\n",
    "#FILTERING COUNTRIES\n",
    "print(\"FILTERING COUNTRIES...\")\n",
    "ph_df = covid_df[covid_df['iso_code']=='PHL'] #PH ONLY\n",
    "world_df = covid_df[covid_df['iso_code'].str.contains('OWID_WRL')] #OVERALL WORLD DATA BY OWID\n",
    "covid_df = covid_df[covid_df['iso_code'].str.contains(re.compile('|'.join(targetCountries)),regex=True)] #ASEAN NATIONS; YOU CAN CHANGE LIST OF COUNTRIES TO FOCUS\n",
    "\n",
    "#FIND TOTAL POPULATION OF ASEAN\n",
    "pop = covid_df[covid_df['date']==dateRange(covid_df)[1]]\n",
    "if(pop.shape[0] != len(targetCountries)): #REFERENCES TO targetCountries\n",
    "    print(\"COUNTRIES!=\",len(targetCountries),\"AT MAX DATE!\")\n",
    "    exit()\n",
    "group_pop = pop['population'].sum()\n",
    "\n",
    "#DATA CLEANUP: NaN->0\n",
    "print(\"DATA CLEANUP (NaN->0)...\")\n",
    "for i in range(0,len(toRetain),1):\n",
    "    covid_df.loc[covid_df[toRetain[i]].isnull(),toRetain[i]]=0\n",
    "\n",
    "#READING CONENTS OF EACH OBSERVATION AVAILABLE OF ALL COUNTRIES AVAILABLE ON A GIVEN DATE \n",
    "#NOT THE MOST EFFICIENT ALGO AS IT RUNS AT O(n*m)\n",
    "#WILL MAKE USE OF THE CURRENT LIST OF COUNTRIES AVAILABLE AT covid_df.\n",
    "print(\"AGGREGATING ASEAN COUNTRIES...\")\n",
    "group_df = aggregator(covid_df,\"MDL_SEA\",NaN,\"Asia\",len(targetCountries)) #Will hold the resulting aggregation of ASEAN countries\n",
    "\n",
    "#ASEAN Checkpoint\n",
    "writeCheckpoint(group_df,\"asean_checkpoint\")\n",
    "\n",
    "#COMBINING ALL SUBDATAFRAMES TO covid_df\n",
    "print(\"COMBINING DATAFRAMES...\")\n",
    "covid_df = pd.concat([group_df, covid_df, world_df])\n",
    "sortbydate(covid_df) #resort by date\n",
    "\n",
    "print(\"Remaining iso_codes:\",covid_df['iso_code'].unique())\n",
    "print(\"FILE PROCESSING COMPLETE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea25cc2",
   "metadata": {},
   "source": [
    "**The following dataframes could be used for the proceeding code:**\n",
    "- covid_df = Combined group_df, world_df, ph_df\n",
    "- group_df = ASEAN countries\n",
    "- world_df = Overall World COVID data\n",
    "- ph_df = Philippine COVID data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84be764f",
   "metadata": {},
   "source": [
    "### 3. Exploratory Data Analysis\n",
    "\n",
    "EDA Questions<br>\n",
    "1. Do case trends increase/decrease on every listed countries by month?\n",
    "2. Is there a correlation between the GDP per capita to hospital and ICU patients of a country?\n",
    "3. Do case numbers correlate negatively with the number of people being vaccinated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a9f5b9",
   "metadata": {},
   "source": [
    "**Numerical Summaries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5749588",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-4a15e9b0e3c6>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-4a15e9b0e3c6>\"\u001b[1;36m, line \u001b[1;32m15\u001b[0m\n\u001b[1;33m    byMonth_df =\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Code for creating days by months\n",
    "def createMonthList(start_year, month_count):\n",
    "    month_list = [] #make use of this\n",
    "    YM = [start_year,0] #[YEAR,MONTH]\n",
    "    for i in range(month_count):\n",
    "        if(YM[1]==12):\n",
    "            YM[0] = YM[0] + 1\n",
    "            YM[1] = 1\n",
    "        else:\n",
    "            YM[0] = YM[0] + 1\n",
    "        val = str(year)+'-'+str(mo)+'-'+'01'\n",
    "        month_list.append(val)\n",
    "    return month_list\n",
    "\n",
    "byMonth_df = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fb6347",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for numerical summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc17186",
   "metadata": {},
   "source": [
    "**Visualizations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8236790d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300b67b0",
   "metadata": {},
   "source": [
    "### 4. Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e34715",
   "metadata": {},
   "source": [
    "1. Is there a significant difference between ASEAN member nations in total and new case numbers?<br><br>\n",
    "    1. Scope in Dataset: Total cases and/or New cases\n",
    "    2. Significance: This is in order to know how the Philippines fare against COVID-19 in comparison to our neighboring countries in the ASEAN as well as in the world."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be207b34",
   "metadata": {},
   "source": [
    "2. Is the government meeting its half-way goal of vaccinating a significant number of people?<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80790ac",
   "metadata": {},
   "source": [
    "### 5. Statistical Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cd8dca",
   "metadata": {},
   "source": [
    "**Hyptothesis**<br><br>\n",
    "\n",
    "$H_0=$ \n",
    "<br>\n",
    "$H_A=$ \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7438fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for formulating statistical inference and hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4bfd26",
   "metadata": {},
   "source": [
    "### 6. Insights and Conclusions\n",
    "\n",
    "{CONENT}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
